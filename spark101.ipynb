{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085b0f1-a7b3-40ff-95c9-8ab1618f5ec5",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Using the repo setup directions, setup a new local and remote repository named spark-exercises. The local version of your repo should live inside of ~/codeup-data-science. This repo should be named spark-exercises\n",
    "\n",
    "Save this work in your spark-exercises repo. Then add, commit, and push your changes.\n",
    "\n",
    "Create a jupyter notebook or python script named spark101 for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dba6ccb4-be42-48dc-975f-77519a99f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import lit, round, col\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e02f865-9225-4555-af01-2ba9405e9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4a3cb9-9c64-4c4c-a639-02e03f8c4fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://rajeshs-air:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb47a50ab20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce2543-8236-4468-ba68-af0ecb4a512f",
   "metadata": {},
   "source": [
    " 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4897a740-6aaf-4e96-af8b-f6c16f0ecbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language\n",
       "0   python\n",
       "1      sql\n",
       "2     ruby\n",
       "3        c\n",
       "4     java\n",
       "5      c++"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create panda dataframe\n",
    "df = pd.DataFrame({\"language\":[\"python\",\"sql\",\"ruby\",\"c\",\"java\",\"c++\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb6d6c2c-2175-4c0e-a4c7-443de5b4879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|     sql|\n",
      "|    ruby|\n",
      "|       c|\n",
      "|    java|\n",
      "|     c++|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now create spark dataframe \n",
    "spark_df= spark.createDataFrame(df)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e6c714-f4f5-4cd3-bcb6-8820ac75655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view schema\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11dd15ca-897f-4844-b499-7056ce669876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataframe, not as simple as pandas\n",
    "#import count\n",
    "from pyspark.sql.functions import count, avg\n",
    "spark_df.count(), len(spark_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc432a1-831f-44f8-9f47-625e7f1bdafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|     sql|\n",
      "|    ruby|\n",
      "|       c|\n",
      "|    java|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show first 5 records\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d950a4e-9cb9-48ad-ba58-7c9dcbd653ee",
   "metadata": {},
   "source": [
    "### 2.Load the mpg dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1d8f37-6cbd-4ab8-8d16-760b13130973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data where mpg resides\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464606a9-af6c-4a23-96d5-a8b622ece699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get mpg pyspark data\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff43ac-2cce-40cd-898d-1dbe0870f624",
   "metadata": {},
   "source": [
    "#### a. Create 1 column of output that contains a message like the one below:\n",
    "    The 1999 audi a4 has a 4 cylinder engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cec78de-8db2-4e5e-a601-eba1cbec39e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|concat                                  |\n",
      "+----------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine|\n",
      "|The 1999 audi a4 has a 4 cylinder engine|\n",
      "|The 2008 audi a4 has a 4 cylinder engine|\n",
      "|The 2008 audi a4 has a 4 cylinder engine|\n",
      "|The 1999 audi a4 has a 6 cylinder engine|\n",
      "+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "mpg.select(concat(lit(\"The \"), \"year\", lit(\" \"), \"manufacturer\",lit(\" \"), \"model\", lit(\" has a \"), \"cyl\", lit(\" cylinder engine\")).alias(\"concat\")).show(5,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc0293-90ff-46dc-b237-a327f9de14f4",
   "metadata": {},
   "source": [
    "#### b. Transform the trans column so that it only contains either manual or auto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8918a501-9e08-438c-953b-6570c0ee9e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   trans|\n",
      "+--------+\n",
      "|auto(l5)|\n",
      "+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\"trans\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5aed9d-d23b-41bf-87ea-1e037883d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|     trans|transmission|\n",
      "+----------+------------+\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "+----------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\"trans\",regexp_extract(\"trans\" , r\"(\\w+)\", 1).alias(\"transmission\")).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2dfac3e-c2dc-48f0-a099-c95d6db053c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|transmission|\n",
      "+------------+\n",
      "|        auto|\n",
      "|      manual|\n",
      "|      manual|\n",
      "|        auto|\n",
      "+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(regexp_extract(\"trans\" , r\"(\\w+)\", 1).alias(\"transmission\")).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f94627-983e-4a1a-bb2f-01b7192b05aa",
   "metadata": {},
   "source": [
    "### 3. Load the tips dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6481e495-ed56-429a-8dc7-76fbcc7bc23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load tips in spark dataframe\n",
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af4844-a995-452f-a476-b90bb1085661",
   "metadata": {},
   "source": [
    "a.What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f05f5d8b-75ce-4a33-bdca-63d899bfb5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "796a3a11-8bb6-4de7-aebe-8ea67ea60526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group by smoker and count\n",
    "tips.groupby(\"smoker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ddab99e1-7eac-4435-b09a-51dd47a831fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|smoker|count|percent|\n",
      "+------+-----+-------+\n",
      "|    No|  151|   0.62|\n",
      "|   Yes|   93|   0.38|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now from groupby and count, make a new columne called percent using withColumn\n",
    "tips.groupby(\"smoker\").count().withColumn(\n",
    "    \"percent\", round(col(\"count\")/tips.count(),2)\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525433f5-57fd-41f8-8294-2e9556b3d99b",
   "metadata": {},
   "source": [
    "b. Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20807c0b-a93c-4fb1-89bf-6e6b3d0ac2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+\n",
      "| tip|total_bill|tip_percent|\n",
      "+----+----------+-----------+\n",
      "|1.01|     16.99|       5.94|\n",
      "|1.66|     10.34|      16.05|\n",
      "| 3.5|     21.01|      16.66|\n",
      "|3.31|     23.68|      13.98|\n",
      "+----+----------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.select(\n",
    "    tips.tip,\n",
    "     tips.total_bill, \n",
    "     round((tips.tip/tips.total_bill * 100),2)\n",
    "    .alias(\"tip_percent\")\n",
    "    ).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd73a73f-04c1-498b-bf13-334a93484287",
   "metadata": {},
   "source": [
    "c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1632949-8e36-4689-a874-04fb43b3d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------------+\n",
      "|   sex|smoker|avg_tip_percent|\n",
      "+------+------+---------------+\n",
      "|  Male|    No|          0.161|\n",
      "|  Male|   Yes|          0.153|\n",
      "|Female|    No|          0.157|\n",
      "|Female|   Yes|          0.182|\n",
      "+------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"sex\",\"smoker\").agg(\n",
    "    round(mean(tips.tip/tips.total_bill),3).alias(\"avg_tip_percent\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92de77f-edd2-4057-baa6-85032473b12f",
   "metadata": {},
   "source": [
    "### 4. Use the seattle weather dataset referenced in the lesson to answer the questions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3dd7c92d-c806-4c37-9801-e4406d2eb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a586880-5812-4d56-80b5-050ada8870c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = data.seattle_weather()\n",
    "weather = spark.createDataFrame(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f3375c6c-4b2f-4b1e-ad3e-5a2b33fca1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aefef-02d5-48ec-a22c-10a45f4da4c7",
   "metadata": {},
   "source": [
    "- Convert the temperatures to fahrenheit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7dff5-fc0f-40de-8eb2-80f2ac25541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c to f: (0°C × 9/5) + 32 = 32°F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ee0fedb9-67ad-418d-80ca-f8e7f60cb9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "|2012-01-06 00:00:00|          2.5|   39.92|   35.96| 2.2|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark rewrites over column if same column name is created\n",
    "weather = weather.withColumn(\n",
    "    \"temp_max\", (weather.temp_max * 9/5 + 32)\n",
    "        ).withColumn(\"temp_min\", (weather.temp_min * 9/5 + 32))\n",
    "weather.show(6)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c3475-c585-47dd-afb5-ee83e5431b4a",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259a26b-5536-462f-b86c-13e0cac58508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b8600-daf8-4c7f-b47a-904a40e43385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
